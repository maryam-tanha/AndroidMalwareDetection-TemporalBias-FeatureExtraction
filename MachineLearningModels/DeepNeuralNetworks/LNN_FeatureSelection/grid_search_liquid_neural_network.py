import torch
import torch.nn as nn
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from skorch import NeuralNetClassifier
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
import pandas as pd
import sys
from sklearn.feature_selection import SelectKBest, chi2

def check_gpu():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    return device

def redirect_stdout_to_file(file_path):
    sys.stdout = open(file_path, 'w')

def load_combined_dataset(file_path):
    df = pd.read_csv(file_path)
    return df

def prepare_data_for_classification(df, target_column):
    X = df.drop(columns=['sha256', target_column]).values
    y = df[target_column].values

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)

    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)
    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)
    y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)
    y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device)

    return X_train, y_train, X_test, y_test

class LNN(nn.Module):
    def __init__(self, input_size, reservoir_size):
        super(LNN, self).__init__()
        self.reservoir_size = reservoir_size
        self.W_in = nn.Linear(input_size, reservoir_size).to(device)
        self.W_res = nn.Linear(reservoir_size, reservoir_size).to(device)
        self.W_out = nn.Linear(reservoir_size, 1).to(device)

    def forward(self, input):
        reservoir = torch.zeros((input.size(0), self.reservoir_size), dtype=input.dtype).to(device)

        input_transformed = self.W_in(input)

        for i in range(input.size(1)):
            if i < self.reservoir_size:
                reservoir = torch.tanh(input_transformed[:, i, None] + self.W_res(reservoir))

        output = torch.sigmoid(self.W_out(reservoir))
        return output

def build_model(x, y):
    input_size = x.shape[1]
    NeuralNet = NeuralNetClassifier(LNN, criterion=nn.BCELoss(), module__input_size=input_size, train_split=False,
                                    device=device)

    pipeline = Pipeline([('nn', NeuralNet)])

    params = {
        # 'nn__max_epochs': [100, 200, 500],
        # 'nn__lr': [0.01, 0.1],
        # 'nn__module__reservoir_size': [1000, 5000, 10000],
        # 'nn__optimizer': [torch.optim.Adam, torch.optim.SGD, torch.optim.RMSprop]}
        'nn__max_epochs': [10],
        'nn__lr': [0.01],
        'nn__module__reservoir_size': [100],
        'nn__optimizer': [torch.optim.Adam]}

    gs = GridSearchCV(pipeline, params, refit=True, cv=3,
                      scoring='roc_auc', verbose=1)

    x_cpu = x.cpu().numpy()
    y_cpu = y.cpu().numpy()

    return gs.fit(x_cpu, y_cpu)

def evaluate_model(model, X_test, y_test):
    print(model)
    X_test_cpu = X_test.cpu().numpy()
    y_test_cpu = y_test.cpu().numpy()

    y_pred = model.predict(X_test_cpu)
    report = classification_report(y_test_cpu, y_pred, zero_division=1)
    print(report)

def feature_selection_and_dataframe(input_file_path, target_column, k_features=263, test_size=0.1, random_state=42):
    # Load your dataset
    df = pd.read_csv(input_file_path)

    # Drop the 'sha256' and target columns for feature selection
    df_features = df.drop(columns=['sha256', target_column])

    # Assume 'target' is the column you want to predict
    X = df_features
    y = df[target_column]

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

    # Perform feature selection using chi-squared test
    selector = SelectKBest(chi2, k=k_features)
    X_train_selected = selector.fit_transform(X_train, y_train)

    # Get the indices of the selected features
    selected_indices = selector.get_support(indices=True)

    # Get the names of the selected features
    selected_feature_names = X.columns[selected_indices]

    # Include the 'sha256' column in the selected features
    selected_feature_names = ['sha256', 'Malware'] + list(selected_feature_names)

    # Create a new DataFrame with the selected features
    df_selected_features = df[selected_feature_names]

    return df_selected_features


def close_stdout():
    sys.stdout.close()

# Main Execution
device = check_gpu()
redirect_stdout_to_file('results.txt')

# Example usage of the function
input_file_path = '../Resources/qa_main_dataset.csv'
target_column = 'Malware'
selected_features_df = feature_selection_and_dataframe(input_file_path, target_column)


X_train, y_train, X_test, y_test = prepare_data_for_classification(selected_features_df, target_column)

model = build_model(X_train, y_train)
print("Best parameters:")
print(model.best_params_)

evaluate_model(model.best_estimator_, X_test, y_test)
close_stdout()
