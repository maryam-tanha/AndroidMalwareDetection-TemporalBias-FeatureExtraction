import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from skorch import NeuralNetClassifier
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
import pandas as pd
import sys

# Check if GPU is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Redirect stdout to a file
sys.stdout = open('results.txt', 'w')

# Load the combined dataset
dataset_path = '../Resources/qa_dataset.csv'
df = pd.read_csv(dataset_path)

# Assuming your target variable is named 'label' and other columns are features
X = df.drop(columns=['sha256', 'Malware']).values
y = df['Malware'].values

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)

# Convert the data to PyTorch tensors and move to GPU
X_train = torch.tensor(X_train, dtype=torch.float32).to(device)
X_test = torch.tensor(X_test, dtype=torch.float32).to(device)
y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)  # whole number needed
y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device)  # for classification.


# Define the Liquid Neural Network (LNN) model for binary classification
class LNN(nn.Module):
    def __init__(self, input_size, reservoir_size):
        super(LNN, self).__init__()
        self.reservoir_size = reservoir_size
        self.W_in = nn.Linear(input_size, reservoir_size).to(device)
        self.W_res = nn.Linear(reservoir_size, reservoir_size).to(device)
        self.W_out = nn.Linear(reservoir_size, 1).to(device)

    def forward(self, input):
        reservoir = torch.zeros((input.size(0), self.reservoir_size), dtype=input.dtype).to(device)

        input_transformed = self.W_in(input)

        for i in range(input.size(1)):
            if i < self.reservoir_size:
                reservoir = torch.tanh(input_transformed[:, i, None] + self.W_res(reservoir))

        output = torch.sigmoid(self.W_out(reservoir))
        return output


def buildModel(x, y):
    input_size = X_train.shape[1]
    NeuralNet = NeuralNetClassifier(LNN, criterion=nn.BCELoss(), module__input_size=input_size, train_split=False,
                                    device=device)

    # The pipeline is instantiated, it wraps scaling and training phase
    pipeline = Pipeline([('nn', NeuralNet)])

    params = {
        'nn__max_epochs': [100, 200, 500],
        'nn__lr': [0.01, 0.1],
        'nn__module__reservoir_size': [1000, 5000, 10000],
        'nn__optimizer': [optim.Adam, optim.SGD, optim.RMSprop]}

    # The grid search module is instantiated
    gs = GridSearchCV(pipeline, params, refit=True, cv=3,
                      scoring='roc_auc', verbose=1)

    # Move the data to CPU before fitting
    x_cpu = x.cpu().numpy()
    y_cpu = y.cpu().numpy()

    return gs.fit(x_cpu, y_cpu)


def evaluateModel(model, X_test, y_test):
    print(model)

    # Move the test data to CPU before prediction
    X_test_cpu = X_test.cpu().numpy()
    y_test_cpu = y_test.cpu().numpy()

    y_pred = model.predict(X_test_cpu)
    report = classification_report(y_test_cpu, y_pred, zero_division=1)
    print(report)


# Build the model.
model = buildModel(X_train, y_train)

print("Best parameters:")
print(model.best_params_)

# Evaluate the model.
evaluateModel(model.best_estimator_, X_test, y_test)
