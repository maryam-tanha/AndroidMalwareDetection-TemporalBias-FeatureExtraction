import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
import pandas as pd
import sys

# Define the Liquid Neural Network (LNN) model for binary classification and move to GPU
class LNN(nn.Module):
    def __init__(self, input_size, reservoir_size, dtype=torch.float32):
        super(LNN, self).__init__()
        self.reservoir_size = reservoir_size
        self.W_in = nn.Linear(input_size, reservoir_size).to(device)
        self.W_res = nn.Linear(reservoir_size, reservoir_size).to(device)
        self.W_out = nn.Linear(reservoir_size, 1).to(device)

    def forward(self, input):
        reservoir = torch.zeros((input.size(0), self.reservoir_size), dtype=input.dtype).to(device)

        # Apply the linear layer to the entire input tensor
        input_transformed = self.W_in(input)

        # Iterate over time (features) and update the reservoir
        for i in range(input.size(1)):
            # Ensure that the index i does not go beyond the reservoir size
            if i < self.reservoir_size:
                reservoir = torch.tanh(input_transformed[:, i, None] + self.W_res(reservoir))

        # Apply the output layer
        output = torch.sigmoid(self.W_out(reservoir))
        return output

def check_gpu():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    return device

def redirect_stdout_to_file(file_path):
    sys.stdout = open(file_path, 'w')

def load_combined_dataset(file_path):
    df = pd.read_csv(file_path)
    return df

def prepare_data_for_classification(df, target_column):
    X = df.drop(columns=['sha256', target_column]).values
    y = df[target_column].values

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)

    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)
    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)

    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)
    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)

    y_train_tensor = y_train_tensor.view(-1, 1)
    y_test_tensor = y_test_tensor.view(-1, 1)

    return X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor

def initialize_model(input_size, reservoir_size):
    model = LNN(input_size, reservoir_size).to(device)
    return model

def train_model(model, train_loader, criterion, optimizer, num_epochs):
    for epoch in range(num_epochs):
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')

def extract_and_print_weights(model):
    input_layer_weights = model.W_in.weight.detach().cpu().numpy()
    reservoir_layer_weights = model.W_res.weight.detach().cpu().numpy()
    output_layer_weights = model.W_out.weight.detach().cpu().numpy()

    print("Input Layer Weights:")
    print(input_layer_weights)

    print("\nReservoir Layer Weights:")
    print(reservoir_layer_weights)

    print("\nOutput Layer Weights:")
    print(output_layer_weights)

def evaluate_model(model, X_test_tensor, y_test_tensor, criterion):
    model.eval()
    with torch.no_grad():
        test_outputs = model(X_test_tensor)
        test_loss = criterion(test_outputs, y_test_tensor)
        print(f'Test Loss: {test_loss.item()}')

        predictions = (test_outputs >= 0.5).float()

        y_true = y_test_tensor.cpu().numpy()
        y_pred = predictions.cpu().numpy()

        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, zero_division=1.0)
        recall = recall_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred)
        auc_roc = roc_auc_score(y_true, test_outputs.cpu().numpy())

        print(f'Accuracy: {accuracy:.4f}')
        print(f'Precision: {precision:.4f}')
        print(f'Recall: {recall:.4f}')
        print(f'F1 Score: {f1:.4f}')
        print(f'AUC-ROC: {auc_roc:.4f}')

def close_stdout():
    sys.stdout.close()

# Main Execution
device = check_gpu()
redirect_stdout_to_file('90_10_results.txt')
df = load_combined_dataset('../Resources/90_10_main_dataset.csv')

X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = prepare_data_for_classification(df, 'Malware')
model = initialize_model(X_train_tensor.shape[1], 100)

criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

train_model(model, train_loader, criterion, optimizer, num_epochs=10)
extract_and_print_weights(model)
evaluate_model(model, X_test_tensor, y_test_tensor, criterion)

close_stdout()
