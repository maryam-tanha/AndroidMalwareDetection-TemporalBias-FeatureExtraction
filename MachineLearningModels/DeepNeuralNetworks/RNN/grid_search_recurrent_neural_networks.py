import torch
import torch.nn as nn
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from skorch import NeuralNetClassifier
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
import pandas as pd
import sys


def check_gpu():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    return device


def redirect_stdout_to_file(file_path):
    sys.stdout = open(file_path, 'w')


def load_combined_dataset(file_path):
    df = pd.read_csv(file_path)
    return df


def prepare_data_for_classification(df, target_column):
    X = df.drop(columns=['sha256', target_column]).values
    y = df[target_column].values

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)

    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)
    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)
    y_train = torch.tensor(y_train, dtype=torch.float32).to(device)
    y_test = torch.tensor(y_test, dtype=torch.float32).to(device)

    return X_train, y_train, X_test, y_test


class SimpleRNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleRNN, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.rnn(x)
        out = out[:, -1, :] if out.dim() == 3 else out
        out = self.fc(out)
        return torch.sigmoid(out)


def build_model(x, y):
    input_size = x.shape[-1]
    output_size = 1
    NeuralNet = NeuralNetClassifier(SimpleRNN, criterion=nn.BCELoss(), module__input_size=input_size,
                                    module__output_size=output_size,
                                    train_split=False, device=device)

    pipeline = Pipeline([('nn', NeuralNet)])

    params = {
        'nn__max_epochs': [10],
        'nn__lr': [0.01],
        'nn__module__hidden_size': [64],
        'nn__optimizer': [torch.optim.Adam]}

    gs = GridSearchCV(pipeline, params, refit=True, cv=3,
                      scoring='roc_auc', verbose=1)

    x_cpu = x.cpu().numpy()
    y_cpu = y.cpu().numpy()

    return gs.fit(x_cpu, y_cpu)


def evaluate_model(model, X_test, y_test):
    print(model)
    X_test_cpu = X_test.cpu().numpy()
    y_test_cpu = y_test.cpu().numpy()

    y_pred = model.predict(X_test_cpu)
    report = classification_report(y_test_cpu, y_pred, zero_division=1)
    print(report)


def close_stdout():
    sys.stdout.close()


# Main Execution
device = check_gpu()
redirect_stdout_to_file('results.txt')
df = load_combined_dataset('../Resources/qa_main_dataset.csv')
X_train, y_train, X_test, y_test = prepare_data_for_classification(df, 'Malware')

# Assuming X_train has shape (batch_size, input_size)
X_train = X_train.unsqueeze(1)  # Add a dimension for sequence_length

y_test = y_test.view(-1, 1)
y_train = y_train.view(-1, 1)

# Assuming X_train and X_test are 3D tensors (batch_size, sequence_length, input_size)
model = build_model(X_train, y_train)
print("Best parameters:")
print(model.best_params_)

evaluate_model(model.best_estimator_, X_test, y_test)
close_stdout()
