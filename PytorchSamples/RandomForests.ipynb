{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1: Predicting Temperature using Random Forest Regressor\n"
      ],
      "metadata": {
        "id": "B9BrLHEqW2f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pandas is used for data manipulation\n",
        "import pandas as pd\n",
        "from   sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Read in data and display first 5 rows\n",
        "features = pd.read_csv('temperatures.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "AkE5yD3lT9Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show all columns.\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "print(features)\n",
        "\n",
        "# One-hot encode the data using pandas get_dummies\n",
        "features = pd.get_dummies(features)\n",
        "\n",
        "# Display the first 5 rows of the last 12 columns.\n",
        "print(features.head(5))\n",
        "\n",
        "# Use numpy to convert to arrays\n",
        "import numpy as np\n",
        "\n",
        "# Labels are the values we want to predict\n",
        "labels = np.array(features['actual'])\n",
        "\n",
        "# Remove the labels from the features\n",
        "# axis 1 refers to the columns\n",
        "features= features.drop('actual', axis = 1)\n",
        "\n",
        "# Saving feature names for later use\n",
        "feature_list = list(features.columns)\n",
        "\n",
        "# Convert to numpy array\n",
        "features = np.array(features)\n",
        "\n",
        "# Using Skicit-learn to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXcdKW-jUQkq",
        "outputId": "f53c9d68-6576-4a50-b0b7-03bf12d8992c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     year  month  day   week  temp_2  temp_1  average  actual  forecast_noaa  forecast_acc  forecast_under  friend\n",
            "0    2016      1    1    Fri      45      45     45.6      45             43            50              44      29\n",
            "1    2016      1    2    Sat      44      45     45.7      44             41            50              44      61\n",
            "2    2016      1    3    Sun      45      44     45.8      41             43            46              47      56\n",
            "3    2016      1    4    Mon      44      41     45.9      40             44            48              46      53\n",
            "4    2016      1    5   Tues      41      40     46.0      44             46            46              46      41\n",
            "..    ...    ...  ...    ...     ...     ...      ...     ...            ...           ...             ...     ...\n",
            "343  2016     12   27   Tues      42      42     45.2      47             41            50              47      47\n",
            "344  2016     12   28    Wed      42      47     45.3      48             41            49              44      58\n",
            "345  2016     12   29  Thurs      47      48     45.3      48             43            50              45      65\n",
            "346  2016     12   30    Fri      48      48     45.4      57             44            46              44      42\n",
            "347  2016     12   31    Sat      48      57     45.5      40             42            48              47      57\n",
            "\n",
            "[348 rows x 12 columns]\n",
            "   year  month  day  temp_2  temp_1  average  actual  forecast_noaa  forecast_acc  forecast_under  friend  week_Fri  week_Mon  week_Sat  week_Sun  week_Thurs  week_Tues  week_Wed\n",
            "0  2016      1    1      45      45     45.6      45             43            50              44      29         1         0         0         0           0          0         0\n",
            "1  2016      1    2      44      45     45.7      44             41            50              44      61         0         0         1         0           0          0         0\n",
            "2  2016      1    3      45      44     45.8      41             43            46              47      56         0         0         0         1           0          0         0\n",
            "3  2016      1    4      44      41     45.9      40             44            48              46      53         0         1         0         0           0          0         0\n",
            "4  2016      1    5      41      40     46.0      44             46            46              46      41         0         0         0         0           0          1         0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training and testing sets\n",
        "train_features, test_features, train_labels, test_labels =\\\n",
        "    train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
        "\n",
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(train_features, train_labels)\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(test_features)\n"
      ],
      "metadata": {
        "id": "Rge0vuLuUWm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the absolute errors\n",
        "errors = abs(predictions - test_labels)\n",
        "\n",
        "# Print out the mean absolute error (mae)\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
        "\n",
        "# Calculate mean absolute percentage error (MAPE)\n",
        "mape = 100 * (errors / test_labels)\n",
        "\n",
        "# Calculate and display accuracy\n",
        "accuracy = 100 - np.mean(mape)\n",
        "\n",
        "print('Accuracy:', round(accuracy, 2), '%.')\n",
        "\n",
        "# Print out the mean square error.\n",
        "mse = mean_squared_error(test_labels, predictions)\n",
        "print('RMSE:', np.sqrt(mse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3GQYWzZUaUf",
        "outputId": "ea807e86-e2af-403b-adcc-859dca4b5022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 3.87 degrees.\n",
            "Accuracy: 93.93 %.\n",
            "RMSE: 5.101657512937373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving Feature Selection using Random Forest Algorithm"
      ],
      "metadata": {
        "id": "_0vg60UtW9Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get numerical feature importances\n",
        "importances = list(rf.feature_importances_)\n",
        "\n",
        "# Present features and importance scores.\n",
        "def showFeatureImportances(importances, feature_list):\n",
        "    dfImportance = pd.DataFrame()\n",
        "    for i in range(0, len(importances)):\n",
        "        dfImportance = dfImportance.append({\"importance\":importances[i],\n",
        "                                            \"feature\":feature_list[i] },\n",
        "                                            ignore_index = True)\n",
        "\n",
        "    dfImportance = dfImportance.sort_values(by=['importance'],\n",
        "                                            ascending=False)\n",
        "    print(dfImportance)\n",
        "showFeatureImportances(importances, feature_list)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMTurVERUcNj",
        "outputId": "21c1e95f-2c11-4330-ea7a-58254bee2974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    importance         feature\n",
            "4     0.655553          temp_1\n",
            "5     0.150330         average\n",
            "6     0.045382   forecast_noaa\n",
            "7     0.034859    forecast_acc\n",
            "8     0.023190  forecast_under\n",
            "2     0.021119             day\n",
            "3     0.020993          temp_2\n",
            "9     0.020685          friend\n",
            "1     0.010330           month\n",
            "12    0.003613        week_Sat\n",
            "10    0.003525        week_Fri\n",
            "11    0.002588        week_Mon\n",
            "15    0.002303       week_Tues\n",
            "13    0.002289        week_Sun\n",
            "16    0.001974        week_Wed\n",
            "14    0.001266      week_Thurs\n",
            "0     0.000000            year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-18-52c23111a00c>:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New random forest with only the two most important variables\n",
        "rf_most_important = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
        "\n",
        "# Extract the two most important features\n",
        "important_indices = [feature_list.index('temp_1'), feature_list.index('average')]\n",
        "train_important = train_features[:, important_indices]\n",
        "test_important = test_features[:, important_indices]\n",
        "\n",
        "# Train the random forest\n",
        "rf_most_important.fit(train_important, train_labels)\n",
        "\n",
        "# Make predictions and determine the error\n",
        "predictions = rf_most_important.predict(test_important)\n",
        "errors = abs(predictions - test_labels)\n",
        "\n",
        "# Display the performance metrics\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
        "mape = np.mean(100 * (errors / test_labels))\n",
        "accuracy = 100 - mape\n",
        "print('Accuracy:', round(accuracy, 2), '%.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otChdg44Ujbr",
        "outputId": "7676181f-37dc-43ee-f77e-0bbbe2d598d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 3.92 degrees.\n",
            "Accuracy: 93.76 %.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################\n",
        "# This revised example shows a more realistic range of hyperparameters.\n",
        "#############################################################\n",
        "# Pandas is used for data manipulation\n",
        "import pandas as pd\n",
        "from   sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Read in data and display first 5 rows\n",
        "features = pd.read_csv('temperatures.csv')\n",
        "\n",
        "# Show all columns.\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "print(features)\n",
        "\n",
        "# One-hot encode the data using pandas get_dummies\n",
        "features = pd.get_dummies(features)\n",
        "\n",
        "# Display the first 5 rows of the last 12 columns.\n",
        "print(features.head(5))\n",
        "\n",
        "# Use numpy to convert to arrays\n",
        "import numpy as np\n",
        "\n",
        "# Labels are the values we want to predict\n",
        "labels = np.array(features['actual'])\n",
        "\n",
        "# Remove the labels from the features\n",
        "# axis 1 refers to the columns\n",
        "features= features.drop('actual', axis = 1)\n",
        "\n",
        "# Saving feature names for later use\n",
        "feature_list = list(features.columns)\n",
        "\n",
        "# Convert to numpy array\n",
        "features = np.array(features)\n",
        "\n",
        "# Using Skicit-learn to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_features, test_features, train_labels, test_labels =\\\n",
        "    train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
        "\n",
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(train_features, train_labels)\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(test_features)\n",
        "\n",
        "# Calculate the absolute errors\n",
        "errors = abs(predictions - test_labels)\n",
        "\n",
        "# Print out the mean absolute error (mae)\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
        "\n",
        "# Calculate mean absolute percentage error (MAPE)\n",
        "mape = 100 * (errors / test_labels)\n",
        "\n",
        "# Calculate and display accuracy\n",
        "accuracy = 100 - np.mean(mape)\n",
        "\n",
        "print('Accuracy:', round(accuracy, 2), '%.')\n",
        "\n",
        "# Print out the mean square error.\n",
        "mse = mean_squared_error(test_labels, predictions)\n",
        "print('RMSE:', np.sqrt(mse))\n",
        "\n",
        "# Get numerical feature importances\n",
        "importances = list(rf.feature_importances_)\n",
        "\n",
        "# Present features and importance scores.\n",
        "def showFeatureImportances(importances, feature_list):\n",
        "    dfImportance = pd.DataFrame()\n",
        "    for i in range(0, len(importances)):\n",
        "        dfImportance = dfImportance.append({\"importance\":importances[i],\n",
        "                                            \"feature\":feature_list[i] },\n",
        "                                            ignore_index = True)\n",
        "\n",
        "    dfImportance = dfImportance.sort_values(by=['importance'],\n",
        "                                            ascending=False)\n",
        "    print(dfImportance)\n",
        "showFeatureImportances(importances, feature_list)\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "random_grid =\\\n",
        "{'bootstrap': [True],\n",
        " 'max_depth': [4,6, None],\n",
        " 'max_features': ['auto'],\n",
        " 'min_samples_leaf': [15],\n",
        " 'min_samples_split': [15],\n",
        " 'n_estimators': [ 400, 800, 1600]}\n",
        "\n",
        "print(random_grid)\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestRegressor()\n",
        "# Random search of parameters, using 3 fold cross validation,\n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(train_features, train_labels)\n",
        "\n",
        "print(\"Best parrameters\")\n",
        "print(rf_random.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMKt9CyfUoQm",
        "outputId": "acfc5ec3-a78a-4847-827d-8d088d0284bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     year  month  day   week  temp_2  temp_1  average  actual  forecast_noaa  forecast_acc  forecast_under  friend\n",
            "0    2016      1    1    Fri      45      45     45.6      45             43            50              44      29\n",
            "1    2016      1    2    Sat      44      45     45.7      44             41            50              44      61\n",
            "2    2016      1    3    Sun      45      44     45.8      41             43            46              47      56\n",
            "3    2016      1    4    Mon      44      41     45.9      40             44            48              46      53\n",
            "4    2016      1    5   Tues      41      40     46.0      44             46            46              46      41\n",
            "..    ...    ...  ...    ...     ...     ...      ...     ...            ...           ...             ...     ...\n",
            "343  2016     12   27   Tues      42      42     45.2      47             41            50              47      47\n",
            "344  2016     12   28    Wed      42      47     45.3      48             41            49              44      58\n",
            "345  2016     12   29  Thurs      47      48     45.3      48             43            50              45      65\n",
            "346  2016     12   30    Fri      48      48     45.4      57             44            46              44      42\n",
            "347  2016     12   31    Sat      48      57     45.5      40             42            48              47      57\n",
            "\n",
            "[348 rows x 12 columns]\n",
            "   year  month  day  temp_2  temp_1  average  actual  forecast_noaa  forecast_acc  forecast_under  friend  week_Fri  week_Mon  week_Sat  week_Sun  week_Thurs  week_Tues  week_Wed\n",
            "0  2016      1    1      45      45     45.6      45             43            50              44      29         1         0         0         0           0          0         0\n",
            "1  2016      1    2      44      45     45.7      44             41            50              44      61         0         0         1         0           0          0         0\n",
            "2  2016      1    3      45      44     45.8      41             43            46              47      56         0         0         0         1           0          0         0\n",
            "3  2016      1    4      44      41     45.9      40             44            48              46      53         0         1         0         0           0          0         0\n",
            "4  2016      1    5      41      40     46.0      44             46            46              46      41         0         0         0         0           0          1         0\n",
            "Mean Absolute Error: 3.87 degrees.\n",
            "Accuracy: 93.93 %.\n",
            "RMSE: 5.101657512937373\n",
            "    importance         feature\n",
            "4     0.655553          temp_1\n",
            "5     0.150330         average\n",
            "6     0.045382   forecast_noaa\n",
            "7     0.034859    forecast_acc\n",
            "8     0.023190  forecast_under\n",
            "2     0.021119             day\n",
            "3     0.020993          temp_2\n",
            "9     0.020685          friend\n",
            "1     0.010330           month\n",
            "12    0.003613        week_Sat\n",
            "10    0.003525        week_Fri\n",
            "11    0.002588        week_Mon\n",
            "15    0.002303       week_Tues\n",
            "13    0.002289        week_Sun\n",
            "16    0.001974        week_Wed\n",
            "14    0.001266      week_Thurs\n",
            "0     0.000000            year\n",
            "{'bootstrap': [True], 'max_depth': [4, 6, None], 'max_features': ['auto'], 'min_samples_leaf': [15], 'min_samples_split': [15], 'n_estimators': [400, 800, 1600]}\n",
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "<ipython-input-21-eaf3f5b0ec08>:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  dfImportance = dfImportance.append({\"importance\":importances[i],\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parrameters\n",
            "{'n_estimators': 800, 'min_samples_split': 15, 'min_samples_leaf': 15, 'max_features': 'auto', 'max_depth': 4, 'bootstrap': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Classification Model using Random Forests:"
      ],
      "metadata": {
        "id": "CZ_KB7EeVAMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Classification Model using Random Forests Classifier:\n",
        "Iris Dataset."
      ],
      "metadata": {
        "id": "r47yK_sjXHxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Load dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Creating a DataFrame of given iris dataset.\n",
        "import pandas as pd\n",
        "data=pd.DataFrame({\n",
        "    'sepal length':iris.data[:,0],\n",
        "    'sepal width':iris.data[:,1],\n",
        "    'petal length':iris.data[:,2],\n",
        "    'petal width':iris.data[:,3],\n",
        "    'species':iris.target\n",
        "})\n",
        "iris['target_names']\n",
        "print(data.head())\n",
        "\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "X=data[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n",
        "y=data['species']  # Labels\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "#Import Random Forest Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "rf=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "#Train the model using the training sets y_pred=rf.predict(X_test)\n",
        "rf.fit(X_train,y_train)\n",
        "\n",
        "y_pred=rf.predict(X_test)\n",
        "\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Predict species for a single flower.\n",
        "# sepal length = 3, sepal width = 5\n",
        "# petal length = 4, petal width = 2\n",
        "prediction = rf.predict([[3, 5, 4, 2]])\n",
        "# 'setosa', 'versicolor', 'virginica'\n",
        "print(prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLBwIsJBVf3b",
        "outputId": "8b6cc2a4-3c73-4b73-b465-6f7e23980bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length  sepal width  petal length  petal width  species\n",
            "0           5.1          3.5           1.4          0.2        0\n",
            "1           4.9          3.0           1.4          0.2        0\n",
            "2           4.7          3.2           1.3          0.2        0\n",
            "3           4.6          3.1           1.5          0.2        0\n",
            "4           5.0          3.6           1.4          0.2        0\n",
            "Accuracy: 0.9777777777777777\n",
            "[2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving Feature Selction and rebuild model"
      ],
      "metadata": {
        "id": "dhyGUzrFXUEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import scikit-learn dataset library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load dataset\n",
        "iris = datasets.load_iris()\n",
        "data = pd.DataFrame({\n",
        "    'sepal length': iris.data[:, 0],\n",
        "    'sepal width': iris.data[:, 1],\n",
        "    'petal length': iris.data[:, 2],\n",
        "    'petal width': iris.data[:, 3],\n",
        "    'species': iris.target\n",
        "})\n",
        "\n",
        "# Show all columns.\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "print(data)\n",
        "X = data[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n",
        "y = data['species']  # Labels\n",
        "feature_list = list(X.columns)\n",
        "# X = np.array(X)\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# Import Random Forest Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=1000)\n",
        "\n",
        "# Train the model using the training sets y_pred=rf.predict(X_test)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Get numerical feature importances\n",
        "importances = list(rf.feature_importances_)\n",
        "\n",
        "# Present features and importance scores.\n",
        "def showFeatureImportances(importances, feature_list):\n",
        "    dfImportance = pd.DataFrame()\n",
        "    for i in range(0, len(importances)):\n",
        "        dfImportance = dfImportance.append({\"importance\": importances[i],\n",
        "                                            \"feature\": feature_list[i]},\n",
        "                                           ignore_index=True)\n",
        "\n",
        "    dfImportance = dfImportance.sort_values(by=['importance'],\n",
        "                                            ascending=False)\n",
        "    print(dfImportance)\n",
        "\n",
        "\n",
        "showFeatureImportances(importances, feature_list)\n",
        "\n",
        "# New random forest with only the two most important variables\n",
        "rf_most_important = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "important_indices = [feature_list.index('petal length'), feature_list.index('petal width'), feature_list.index('sepal '\n",
        "                                                                                                               'length')]\n",
        "\n",
        "train_important = X_train[:, important_indices]\n",
        "test_important = X_test[:, important_indices]\n",
        "\n",
        "# Train the random forest\n",
        "rf_most_important.fit(train_important, y_train)\n",
        "\n",
        "# Make predictions and determine the error\n",
        "predictions = rf_most_important.predict(test_important)\n",
        "errors = abs(predictions - y_test)\n",
        "\n",
        "# Display the performance metrics\n",
        "mape = np.mean(100 * (errors / y_test))\n",
        "accuracy = 100 - mape\n",
        "print('Accuracy:', round(accuracy, 2), '%.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UtZfFHOVlnh",
        "outputId": "74b7e9af-0bd6-45fa-ef31-752ecc272261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal length  sepal width  petal length  petal width  species\n",
            "0             5.1          3.5           1.4          0.2        0\n",
            "1             4.9          3.0           1.4          0.2        0\n",
            "2             4.7          3.2           1.3          0.2        0\n",
            "3             4.6          3.1           1.5          0.2        0\n",
            "4             5.0          3.6           1.4          0.2        0\n",
            "..            ...          ...           ...          ...      ...\n",
            "145           6.7          3.0           5.2          2.3        2\n",
            "146           6.3          2.5           5.0          1.9        2\n",
            "147           6.5          3.0           5.2          2.0        2\n",
            "148           6.2          3.4           5.4          2.3        2\n",
            "149           5.9          3.0           5.1          1.8        2\n",
            "\n",
            "[150 rows x 5 columns]\n",
            "Accuracy:  0.9555555555555556\n",
            "   importance       feature\n",
            "3    0.461026   petal width\n",
            "2    0.412324  petal length\n",
            "0    0.089553  sepal length\n",
            "1    0.037097   sepal width\n",
            "Accuracy: 95.96 %.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c2Njv8JUWWqn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}