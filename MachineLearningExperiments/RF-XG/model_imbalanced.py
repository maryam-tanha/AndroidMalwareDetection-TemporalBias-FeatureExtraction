from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score,roc_auc_score, confusion_matrix
from sklearn.model_selection import GridSearchCV
import pandas as pd
from xgboost import XGBClassifier
import sys

from sklearn.model_selection import train_test_split
#from sklearn.feature_selection import SelectKBest, chi2
import datetime




def redirect_stdout_to_file(file_path):
    sys.stdout = open(file_path, 'w')
    
def load_combined_dataset(file_path):
	df = pd.read_csv(file_path)
	return df


def prepare_data_for_classification(df, target_column):
    X = df.drop(columns=['sha256', target_column]).values
    y = df[target_column].values

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)
    
    
    return X_train, y_train, X_test, y_test
    


def build_and_evaluate_model():
    

     # Parameter Grid for Random Forest
    param_grid_rf = {
        'n_estimators': [50, 100, 200, 500, 1000],
        'max_depth': [None, 10, 16, 20, 30, 40],
        'min_samples_split': [2, 5, 10, 20, 50]
    }


    # Define the parameter grid for XGBoost
    param_grid_xgb = {
        'n_estimators': [50, 100, 200, 500],
        'max_depth': [3, 6, 9, 12],
        'learning_rate': [0.001, 0.01, 0.1, 0.3],
        'subsample': [0.5, 0.8, 1.0],
        'colsample_bytree': [0.5, 0.8, 1.0]
    }

    rf_model = RandomForestClassifier()
    xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')

    grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, verbose=2, n_jobs=-1)
    grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=5, verbose=2, n_jobs=-1)

    # Fit the models
    grid_search_rf.fit(X_train, y_train)
    grid_search_xgb.fit(X_train, y_train)

    # Predict and evaluate using the best model
    best_rf = grid_search_rf.best_estimator_
    best_xgb = grid_search_xgb.best_estimator_
    
    print("================RANDOM FOREST RESULTS===================:")
    rf_test_predictions = best_rf.predict(X_test)
    rf_train_predictions = best_rf.predict(X_train)
    
    print("Best Parameters: ", grid_search_rf.best_params_)
    
    train_accuracy = accuracy_score(y_train, rf_train_predictions)
    test_accuracy = accuracy_score(y_test, rf_test_predictions)
    
    train_precision = precision_score(y_train, rf_train_predictions)
    test_precision = precision_score(y_test, rf_test_predictions)
    
    train_recall = recall_score(y_train, rf_train_predictions)
    test_recall = recall_score(y_test, rf_test_predictions)
    
    train_f1 = f1_score(y_train, rf_train_predictions)
    test_f1 = f1_score(y_test, rf_test_predictions)
    
    train_probs = best_rf.predict_proba(X_train)[:, 1]  
    test_probs = best_rf.predict_proba(X_test)[:, 1]
    
    train_roc_auc = roc_auc_score(y_train, train_probs)
    test_roc_auc = roc_auc_score(y_test, test_probs)
    
    train_conf_matrix = confusion_matrix(y_train, rf_train_predictions)
    test_conf_matrix = confusion_matrix(y_test, rf_test_predictions)
    
    print(f"Training Accuracy: {train_accuracy}, Test Accuracy: {test_accuracy}")
    print(f"Training Precision: {train_precision}, Test Precision: {test_precision}")
    print(f"Training Recall: {train_recall}, Test Recall: {test_recall}")
    print(f"Training F1 Score: {train_f1}, Test F1 Score: {test_f1}")
    print(f"Training ROC-AUC: {train_roc_auc}, Test ROC-AUC: {test_roc_auc}")
    print(f"Training Confusion Matrix:\n{train_conf_matrix}")
    print(f"Test Confusion Matrix:\n{test_conf_matrix}")
    
    #------------------------------------
    print(classification_report(y_test, rf_test_predictions, labels=[0, 1], target_names=["Benign", "Malware"]))
    print(classification_report(y_train, rf_train_predictions, labels=[0, 1], target_names=["Benign", "Malware"]))
    
    # Create a test results DataFrame
    
    #test_results_rf = pd.DataFrame({'SHA256': X_test['SHA256'], 'Actual Malware': y_test, 'Predicted label':rf_test_predictions})
    
    #test_results_rf = pd.concat([test_results_rf, X_test], axis=1)
    
    #test_results_rf.to_csv('test_dataset_predictions_rf.csv', index=False)
    
    
    print("================XGB BOOST RESULTS===================:")
    xgb_test_predictions = best_xgb.predict(X_test)
    xgb_train_predictions = best_xgb.predict(X_train)
    print("Best Parameters: ", grid_search_xgb.best_params_)
    
    print("Precision (Malware):", precision_score(y_test, xgb_test_predictions, pos_label=1))
    print("Recall (Malware):", recall_score(y_test, xgb_test_predictions, pos_label=1))
    print("F1 Score (Malware):", f1_score(y_test, xgb_test_predictions, pos_label=1))
    
    train_accuracy = accuracy_score(y_train, xgb_train_predictions)
    test_accuracy = accuracy_score(y_test, xgb_test_predictions)
    
    train_precision = precision_score(y_train, xgb_train_predictions)
    test_precision = precision_score(y_test, xgb_test_predictions)
    
    train_recall = recall_score(y_train, xgb_train_predictions)
    test_recall = recall_score(y_test, xgb_test_predictions)
    
    train_f1 = f1_score(y_train, xgb_train_predictions)
    test_f1 = f1_score(y_test, xgb_test_predictions)
    
    train_probs = best_xgb.predict_proba(X_train)[:, 1]  
    test_probs = best_xgb.predict_proba(X_test)[:, 1]
    
    train_roc_auc = roc_auc_score(y_train, train_probs)
    test_roc_auc = roc_auc_score(y_test, test_probs)
    
    train_conf_matrix = confusion_matrix(y_train, xgb_train_predictions)
    test_conf_matrix = confusion_matrix(y_test, xgb_test_predictions)
    
    print(f"Training Accuracy: {train_accuracy}, Test Accuracy: {test_accuracy}")
    print(f"Training Precision: {train_precision}, Test Precision: {test_precision}")
    print(f"Training Recall: {train_recall}, Test Recall: {test_recall}")
    print(f"Training F1 Score: {train_f1}, Test F1 Score: {test_f1}")
    print(f"Training ROC-AUC: {train_roc_auc}, Test ROC-AUC: {test_roc_auc}")
    print(f"Training Confusion Matrix:\n{train_conf_matrix}")
    print(f"Test Confusion Matrix:\n{test_conf_matrix}")
    
    print(classification_report(y_test, xgb_test_predictions, labels=[0, 1], target_names=["Benign", "Malware"]))
    print(classification_report(y_train, xgb_train_predictions, labels=[0, 1], target_names=["Benign", "Malware"]))
    
    
    # Create a test results DataFrame
    
    #test_results_xgb = pd.DataFrame({'SHA256': X_test['SHA256'], 'Actual Malware': y_test, 'Predicted label':xgb_test_predictions})
    
    #test_results_xgb = pd.concat([test_results_xgb, X_test], axis=1)
    
    #test_results_xgb.to_csv('test_dataset_predictions_xgb.csv', index=False)
    
    return


 


def close_stdout():
    sys.stdout.close()

# Main Execution
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
redirect_stdout_to_file('results_imbalanced_' + timestamp + '.txt')

target_column = 'Malware'
df = load_combined_dataset('../Resources/90_10_main_dataset.csv')
# Calculating the ratio of benign to malware APKs
malware_column = df['Malware']
ratio_ones_to_zeroes = malware_column.value_counts(normalize=True)
print("Ratio of Benign APKs to Malware APKs:")
print(ratio_ones_to_zeroes)

X_train, y_train, X_test, y_test = prepare_data_for_classification(df, 'Malware')
#test_sha256_list = X_test['sha256']


build_and_evaluate_model()

print(f'DateTime: {timestamp}.')

close_stdout()






