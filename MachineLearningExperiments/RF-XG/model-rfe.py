from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score,roc_auc_score, confusion_matrix
from sklearn.model_selection import GridSearchCV
import pandas as pd
from xgboost import XGBClassifier
import sys

from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest, chi2
import datetime

from sklearn.feature_selection import RFE
from sklearn.pipeline import Pipeline



def redirect_stdout_to_file(file_path):
    sys.stdout = open(file_path, 'w')



def prepare_data_for_classification(training_data, test_data):

    train = pd.DataFrame(training_data)
    test = pd.DataFrame(test_data)
    # Randomly shuffling the rows of the dataframes
    train = train.sample(frac=1, random_state=42)  # Setting a random seed for reproducibility
    test = test.sample(frac=1, random_state=42)  # Setting a random seed for reproducibility
    train.reset_index(drop=True, inplace=True)
    test.reset_index(drop=True, inplace=True)

    # Calculating the ratio of benign to malware APKs in training set
    malware_column_train = train['Malware']
    ratio_ones_to_zeroes = malware_column_train.value_counts(normalize=True)
    print("TRAINING SET: Ratio of Benign APKs to Malware APKs:")
    print(ratio_ones_to_zeroes)

    # Calculating the ratio of benign to malware APKs
    malware_column_test = test['Malware']
    ratio_ones_to_zeroes = malware_column_test.value_counts(normalize=True)
    print("TEST SET: Ratio of Benign APKs to Malware APKs:")
    print(ratio_ones_to_zeroes)

    
    test_sha256_list = test['sha256']
    
    # Set display options
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    train = train.drop(['sha256'], axis=1)
    test = test.drop(['sha256'], axis=1)

    # Print the names of all columns
    column_names = train.columns
    column_names_list = column_names.to_list()

    for col in column_names_list:
        train[col] = train[col].astype(int)
        test[col] = test[col].astype(int)

    # Split data into features and target
    X_train = train.drop(columns=['Malware'])
    y_train = train['Malware']

    # Split data into features and target
    X_test = test.drop(columns=['Malware'])
    y_test = test['Malware']


    
    return X_train, y_train, X_test, y_test, test_sha256_list




def build_and_evaluate_model():
	
	rf_model = RandomForestClassifier(random_state=42)
	rfe = RFE(estimator=rf_model)
	
	pipeline = Pipeline([('rfe', rfe), ('classifier', rf_model)])
	
	param_grid_rf = {
        'classifier__n_estimators': [50, 100, 200, 500, 1000],
        'classifier__max_depth': [None, 10, 16, 20, 30, 40],
        'classifier__min_samples_split': [2, 5, 10, 20, 50],
        'rfe__n_features_to_select': [100, 200, 300, 400, 500]  # Number of features to select with RFE
    }
	grid_search_rf = GridSearchCV(pipeline, param_grid_rf, cv=5, verbose=2, n_jobs=-1) 
	
	grid_search_rf.fit(X_train, y_train)
	best_n_features = grid_search_rf.best_estimator_.n_features_
	print("Best number of features:", best_n_features)
	print(f"The number of selected features is {best_n_features}.")
	best_model = grid_search_rf.best_estimator_
	selected_features = best_model.support_
	selected_feature_names = feature_names[selected_features]
	print("Names of Selected Features:", selected_feature_names)
	
	print("================RANDOM FOREST RESULTS===================:")
	rf_test_predictions = best_model.predict(X_test)
	rf_train_predictions = best_model.predict(X_train)
	
	print("Best Parameters: ", grid_search_rf.best_params_)
    
	train_accuracy = accuracy_score(y_train, rf_train_predictions)
	test_accuracy = accuracy_score(y_test, rf_test_predictions)

	train_precision = precision_score(y_train, rf_train_predictions)
	test_precision = precision_score(y_test, rf_test_predictions)

	train_recall = recall_score(y_train, rf_train_predictions)
	test_recall = recall_score(y_test, rf_test_predictions)

	train_f1 = f1_score(y_train, rf_train_predictions)
	test_f1 = f1_score(y_test, rf_test_predictions)

	train_probs = best_rf.predict_proba(X_train)[:, 1]  
	test_probs = best_rf.predict_proba(X_test)[:, 1]

	train_roc_auc = roc_auc_score(y_train, train_probs)
	test_roc_auc = roc_auc_score(y_test, test_probs)

	train_conf_matrix = confusion_matrix(y_train, rf_train_predictions)
	test_conf_matrix = confusion_matrix(y_test, rf_test_predictions)
    
	print(f"Training Accuracy: {train_accuracy}, Test Accuracy: {test_accuracy}")
	print(f"Training Precision: {train_precision}, Test Precision: {test_precision}")
	print(f"Training Recall: {train_recall}, Test Recall: {test_recall}")
	print(f"Training F1 Score: {train_f1}, Test F1 Score: {test_f1}")
	print(f"Training ROC-AUC: {train_roc_auc}, Test ROC-AUC: {test_roc_auc}")
	print(f"Training Confusion Matrix:\n{train_conf_matrix}")
	print(f"Test Confusion Matrix:\n{test_conf_matrix}")

    
	print(classification_report(y_test, rf_test_predictions, labels=[0, 1], target_names=["Benign", "Malware"]))
	print(classification_report(y_train, rf_train_predictions, labels=[0, 1], target_names=["Benign", "Malware"]))

	# Create a test results DataFrame

	test_results_rf = pd.DataFrame({'SHA256': test_sha256, 'Actual Malware': y_test, 'Predicted label':rf_test_predictions})

	test_results_rf = pd.concat([test_results_rf, X_test], axis=1)

	test_results_rf.to_csv('test_dataset_predictions_rf.csv', index=False)  

    
	return


 


def close_stdout():
    sys.stdout.close()

# Main Execution
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")



redirect_stdout_to_file('results_' + timestamp + '.txt')


# Example usage of the function
# input_file_path = '/Users/khushbeen/PycharmProjects/StaticAndroidMalwareAnalysis/MachineLearningModels/FeatureSelection/Resources/qa_dataset.csv'
input_train_path = '../Resources/50_50_train_dataset.csv'
input_test_path = '../Resources/90_10_test_dataset.csv'
target_column = 'Malware'

train_features_df = pd.read_csv(input_train_path)
test_features_df = pd.read_csv(input_test_path)
print(f'Train set size: {train_features_df.shape}.')
print(f'Test set size: {test_features_df.shape}.')
	

X_train, y_train, X_test, y_test, test_sha256 = prepare_data_for_classification(train_features_df, test_features_df)

feature_names = X_train.columns
print(feature_names)

build_and_evaluate_model()

print(f'DateTime: {timestamp}.')

close_stdout()






