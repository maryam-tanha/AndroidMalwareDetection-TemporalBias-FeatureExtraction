import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import classification_report
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from skorch import NeuralNetClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
import pandas as pd
import sys
from scipy.stats import randint, uniform

# Check if GPU is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Redirect stdout to a file
sys.stdout = open('results.txt', 'w')

# Load the combined dataset
dataset_path = '../Resources/qa_dataset.csv'
df = pd.read_csv(dataset_path)

# Assuming your target variable is named 'label' and other columns are features
X = df.drop(columns=['sha256', 'Malware']).values
y = df['Malware'].values

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)

# Convert the data to PyTorch tensors
X_train = torch.tensor(X_train, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32)  # whole number needed
y_test = torch.tensor(y_test, dtype=torch.float32)  # for classification.

# Modify the target tensor size to match the model output size
y_train = y_train.view(-1, 1)
y_test = y_test.view(-1, 1)

# Define the Liquid Neural Network (LNN) model for binary classification
class LNN(nn.Module):
    def __init__(self, input_size, reservoir_size):
        super(LNN, self).__init__()
        self.reservoir_size = reservoir_size
        self.W_in = nn.Linear(input_size, reservoir_size)
        self.W_res = nn.Linear(reservoir_size, reservoir_size)
        self.W_out = nn.Linear(reservoir_size, 1)

    def forward(self, input):
        reservoir = torch.zeros((input.size(0), self.reservoir_size), dtype=input.dtype)

        input_transformed = self.W_in(input)

        for i in range(input.size(1)):
            if i < self.reservoir_size:
                reservoir = torch.tanh(input_transformed[:, i, None] + self.W_res(reservoir))

        output = torch.sigmoid(self.W_out(reservoir))
        return output

def buildModel(x, y):
    input_size = X_train.shape[1]
    NeuralNet = NeuralNetClassifier(LNN, criterion=nn.BCELoss(), module__input_size=input_size, train_split=False, device=device)

    # The pipeline is instantiated, it wraps scaling and training phase
    pipeline = Pipeline([('nn', NeuralNet)])

    # Specify parameter distributions instead of a grid
    params = {
        'nn__max_epochs': randint(5, 30),
        'nn__lr': uniform(0.01, 0.1),
        'nn__module__reservoir_size': randint(10, 100),
        'nn__optimizer__lr': uniform(0.001, 0.01)
    }

    # The randomized search module is instantiated
    rs = RandomizedSearchCV(pipeline, params, n_iter=10, scoring='roc_auc', cv=3, verbose=1, random_state=42)
    return rs.fit(x, y)

def evaluateModel(model, X_test, y_test):
    print(model)
    y_pred = model.predict(X_test)
    report = classification_report(y_test, y_pred, zero_division=1)
    print(report)

# Build the model.
model = buildModel(X_train, y_train)

print("Best parameters:")
print(model.best_params_)

# Evaluate the model.
evaluateModel(model.best_estimator_, X_test, y_test)
