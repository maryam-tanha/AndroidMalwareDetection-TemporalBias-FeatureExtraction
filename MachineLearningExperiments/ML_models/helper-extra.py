
import pandas as pd
import numpy as np

from sklearn.feature_selection import RFE




    
def remove_constant_features(df1, df2):
	#	 Identify constant categorical features
	constant_categorical_features1 = [col for col in df1.columns if df1[col].nunique() == 1 and df1[col].dtype == 'object']
	constant_categorical_features2 = [col for col in df2.columns if df2[col].nunique() == 1 and df2[col].dtype == 'object']
	if constant_categorical_features1 == constant_categorical_features2:
		
		print(f"There are {len(constant_categorical_features1)} constant categorical features and we remove them!")
		print(f"Removed features are: {constant_categorical_features1}.")

		# Drop constant categorical features from the DataFrame
		df1 = df1.drop(columns=constant_categorical_features1)
		# Drop constant categorical features from the DataFrame
		df2 = df2.drop(columns=constant_categorical_features2)
		
	return df1, df2



def feature_selection_and_dataframe(input_train_path, input_test_path, target_column, k_features=10):
    # Load your dataset
    train_dataset = pd.read_csv(input_train_path)
    test_dataset = pd.read_csv(input_test_path)

    # Drop the 'sha256' and target columns for feature selection
    df_train_features = train_dataset

    # Assume 'target' is the column you want to predict
    X_train = df_train_features.drop(columns=['sha256', target_column])
    y_train = df_train_features[target_column]
    
    
    X_train_APICalls = df_train_features.drop(df_train_features.iloc[:, 0:350], axis=1)
    print(f'Size of data frame that contains API Calls is {X_train_APICalls.shape}.')
    print(f'The original number of API Calls is {X_train_APICalls.shape[1]}.')
    
    
    X_train_manifest_properties = df_train_features.drop(df_train_features.iloc[:, 350:], axis=1)
    selected_feature_manifest = list(X_train_manifest_properties.columns.values)
    print(f'Number of manifest properties is {len(selected_feature_manifest)}.')
    
    


    # Perform feature selection using chi-squared test
    selector = SelectKBest(chi2, k=k_features)
    X_train_selected = selector.fit_transform(X_train_APICalls, y_train)
    print(f'Number of selected API Calls is {k_features}.')

    # Get the indices of the selected features
    selected_indices = selector.get_support(indices=True)

    # Get the names of the selected features
    selected_feature_names_api_calls = X_train_APICalls.columns[selected_indices]

    # 'sha256' and 'malware' columns are already included in the selected_feature_manifest
    selected_feature_names = list(selected_feature_manifest)+list(selected_feature_names_api_calls)
    print(f' The total number of selected features is {len(selected_feature_names) - 2}.') # We deduct 2 because the features include sha256 and Malware columns
    print(f'\n Selected features: {selected_feature_names}.')

    # Create a new DataFrame with the selected features
    df_selected_train_features = train_dataset[selected_feature_names]
    df_selected_test_features = test_dataset[selected_feature_names]

    return df_selected_train_features, df_selected_test_features
    
    
    
def build_and_evaluate_model():

	#print("\n========================================================== Random Forest =======================================================================:")
	#model_name = "RF"
	# Parameter Grid for Random Forest
	#param_grid_rf = {
	#	'n_estimators': [50, 100, 200, 500, 1000],
	#	'max_depth': [None, 5, 10, 16, 20, 30, 40],
	#	'min_samples_split': [2, 5, 10, 20, 50]
	#}
	
		
	#rf_model = RandomForestClassifier(class_weight='balanced')
	
	#grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1', verbose=2, n_jobs=-1)

	# Fit the models
	#grid_search_rf.fit(X_train, y_train)


	# Predict and evaluate using the best model
	#best_rf = grid_search_rf.best_estimator_
	#print("Best Parameters: ", grid_search_rf.best_params_)
	
	#compute_model_results(model_name, best_rf)
	
	#print("\n=========================================================== XGBoost =======================================================================:")
	#model_name = "XGB"
	
	# Define the parameter grid for XGBoost
	#param_grid_xgb = {
    #    'n_estimators': [50, 100, 200, 500, 1000],
    #    'max_depth': [3, 6, 9, 12],
    #    'learning_rate': [0.001, 0.01, 0.1, 0.3],
     #   'subsample': [0.5, 0.8, 1.0],
     #   'colsample_bytree': [0.5, 0.8, 1.0]
    #}

	#ratio = 9 # 9000/1000 , we have 9000 benign apps (negative class) and 1000 malware
		
	#xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=ratio)
	
	#grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=5, scoring='f1', verbose=2, n_jobs=-1)
	#grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=5, scoring='roc_auc', verbose=2, n_jobs=-1)
	
	
	#grid_search_xgb.fit(X_train, y_train)
	
	#best_xgb = grid_search_xgb.best_estimator_
	#print("Best Parameters for XGBoost: ", grid_search_xgb.best_params_)
	
	#compute_model_results(model_name, best_xgb)
	
	print("\n=========================================================== LGBM===================================================================:")
	model_name = "LGBM"
	
	

	param_grid_lgbm = {
    #'learning_rate': [0.001, 0.01, 0.1],
    'learning_rate': [0.01],
    #'n_estimators': [50, 100, 150],
    'n_estimators': [100],
    'max_depth': [15],
    'num_leaves':[32]
    #'colsample_bytree': [0.7, 0.8, 0.9],
    #'subsample': [0.7, 0.8, 0.9],
    #'min_child_samples': [1, 5, 10],
   
}

	#lgbm_model = LGBMClassifier(objective='binary',random_state=42, scale_pos_weight =9) 
	lgbm_model = LGBMClassifier(objective='binary',random_state=42, is_unbalance=True, device='gpu')
	
	grid_search_lgbm = GridSearchCV(lgbm_model, param_grid_lgbm, cv=5, scoring='f1', verbose=2, n_jobs=-1)
	
	grid_search_lgbm.fit(X_train, y_train)
	
	best_lgbm = grid_search_lgbm.best_estimator_
	
	compute_model_results(model_name, best_lgbm)
	
	
	
	return 

