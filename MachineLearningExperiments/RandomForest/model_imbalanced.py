from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score,roc_auc_score, confusion_matrix, precision_recall_curve
from sklearn.model_selection import GridSearchCV
import pandas as pd
import sys
from sklearn.model_selection import train_test_split
import datetime

def redirect_stdout_to_file(file_path):
    sys.stdout = open(file_path, 'w')
    
def load_combined_dataset(file_path):
	df = pd.read_csv(file_path)
	return df



    
def prepare_data_for_classification(df, target_column):

	
	X = df.drop(target_column, axis=1)

	y = df[target_column]
	
	X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)

	# We want to store the SHA256 values for the test set set only
	#y_test = y_test.values
	#y_train=y_train.values
	
	
	test_sha256_list = X_test['sha256'].values
	
	
	
	X_test.to_csv('test_dataset_rf_imbalanced_'+ timestamp +'.csv', index=False)
	
	
	X_test = X_test.drop(columns=['sha256'])
	temp_train = X_train.drop(columns=['sha256'])
	
	temp_train = pd.concat([temp_train, y_train], axis=1)
	X_train = X_train.drop(columns=['sha256'])
	

	return X_train, y_train, X_test, y_test, test_sha256_list, temp_train
    

def build_and_evaluate_model(enable_cl_weight):
    

	param_grid_rf = {
		'n_estimators': [50, 100, 200, 500, 1000],
		'max_depth': [None, 10, 16, 20, 30, 40],
		'min_samples_split': [2, 5, 10, 20, 50]
	}
	
	
	
	if enable_cl_weight:
		rf_model = RandomForestClassifier(class_weight='balanced')
	else:
		rf_model = RandomForestClassifier()

	grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1', verbose=2, n_jobs=-1)

	# Fit the models
	grid_search_rf.fit(X_train, y_train)


	# Predict and evaluate using the best model
	best_rf = grid_search_rf.best_estimator_


	print("================RANDOM FOREST RESULTS===================:")
	rf_test_predictions = best_rf.predict(X_test)
	rf_train_predictions = best_rf.predict(X_train)

	print("Best Parameters: ", grid_search_rf.best_params_)

	train_accuracy = accuracy_score(y_train, rf_train_predictions)
	test_accuracy = accuracy_score(y_test, rf_test_predictions)

	train_precision = precision_score(y_train, rf_train_predictions)
	test_precision = precision_score(y_test, rf_test_predictions)

	train_recall = recall_score(y_train, rf_train_predictions)
	test_recall = recall_score(y_test, rf_test_predictions)

	train_f1 = f1_score(y_train, rf_train_predictions)
	test_f1 = f1_score(y_test, rf_test_predictions)

	train_probs = best_rf.predict_proba(X_train)[:, 1]  
	test_probs = best_rf.predict_proba(X_test)[:, 1]

	train_roc_auc = roc_auc_score(y_train, train_probs)
	test_roc_auc = roc_auc_score(y_test, test_probs)

	train_conf_matrix = confusion_matrix(y_train, rf_train_predictions)
	test_conf_matrix = confusion_matrix(y_test, rf_test_predictions)
	#The order in output
	#[[TN, FP],
	#[FN, TP]]
	TN, FP, FN, TP = test_conf_matrix.ravel()

	print(f"Training Accuracy: {train_accuracy}, Test Accuracy: {test_accuracy}")
	print(f"Training Precision: {train_precision}, Test Precision: {test_precision}")
	print(f"Training Recall: {train_recall}, Test Recall: {test_recall}")
	print(f"Training F1 Score: {train_f1}, Test F1 Score: {test_f1}")
	print(f"Training ROC-AUC: {train_roc_auc}, Test ROC-AUC: {test_roc_auc}")
	print(f"Training Confusion Matrix:\n{train_conf_matrix}")
	print(f"Test Confusion Matrix:\n{test_conf_matrix}")
	print("For test dataset:")
	print(f"True Negatives (TN): {TN}")
	print(f"False Positives (FP): {FP}")
	print(f"False Negatives (FN): {FN}")
	print(f"True Positives (TP): {TP}")

	#------------------------------------
	print(classification_report(y_test, rf_test_predictions, labels=[0, 1], target_names=["Benign", "Malware"]))
	
	# Create a test results DataFrame

	test_results_rf = pd.DataFrame({'SHA256': test_sha256, 'Actual Malware': y_test, 'Predicted label':rf_test_predictions})
	

	#Extract the SHA256 hashes for FPs, FNs, TPs, TNs
	
	fp_hashes = []
	fn_hashes = []
	tn_hashes = []
	tp_hashes = []
	
	for index, row in test_results_rf.iterrows():
		if row['Actual Malware'] == 0 and row['Predicted label'] == 1:
			fp_hashes.append(row['SHA256'])
		elif row['Actual Malware'] == 1 and row['Predicted label'] == 0:	
			fn_hashes.append(row['SHA256'])
		elif row['Actual Malware'] == 0 and row['Predicted label'] == 0:
			tn_hashes.append(row['SHA256'])
		elif row['Actual Malware'] == 1 and row['Predicted label'] == 1:
			tp_hashes.append(row['SHA256'])

	print(f"SHA256 hashes for False Positives (FP): {fp_hashes}")
	print(f"Number of False Positives (FP): {len(fp_hashes)}")
		
	print(f"SHA256 hashes for False Negatives (FN): {fn_hashes}")
	print(f"Number of False Negatives (FN): {len(fn_hashes)}")
	
	#print(f"SHA256 hashes for True Negatives (TN): {tn_hashes}")
	print(f"Number of True Negatives (TN): {len(tn_hashes)}")
	
	#print(f"SHA256 hashes for True Positives (TP): {tp_hashes}")
	print(f"Number of True Positives (TP): {len(tp_hashes)}")
	
	#Only include the sha256, target column and prediction label
	if enable_cl_weight:
		test_results_rf.to_csv('test_dataset_predictions_rf_imbalanced_classweight_'+ timestamp +'.csv', index=False)
	else:
		test_results_rf.to_csv('test_dataset_predictions_rf_imbalanced_'+ timestamp +'.csv', index=False)
	
	
	
	fp_indices = [i for i in range(len(y_test)) if y_test.iloc[i] == 0 and rf_test_predictions[i] == 1]
	fn_indices = [i for i in range(len(y_test)) if y_test.iloc[i] == 1 and rf_test_predictions[i] == 0]
	tn_indices = [i for i in range(len(y_test)) if y_test.iloc[i] == 0 and rf_test_predictions[i] == 0]
	tp_indices = [i for i in range(len(y_test)) if y_test.iloc[i] == 1 and rf_test_predictions[i] == 1]
	

	
	
	false_negative_indices_new  = []  #stores a subset of FNs in which atleast one feature is equal to one
	
	for idx in range(len(fn_indices)):
		# Choose one of the false negatives (e.g., the first one)
		
		chosen_index = fn_indices[idx]

		# Get the feature values for the chosen false negative instance
		chosen_instance_features = X_test.iloc[chosen_index]

		
		for column_name, value in chosen_instance_features.items():
			if value == 1:
				#print(column_name)
				if chosen_index not in false_negative_indices_new:
					false_negative_indices_new.append(chosen_index)
					

	# Print the indexes of false negatives
	print(f"Filtered FN indices: {false_negative_indices_new }")
	print(f"Number of filtered FNs: {len(false_negative_indices_new) }")
	
	false_positive_indices_new  = []  #stores a subset of FPs in which atleast one feature is equal to one
	
	
	for idx in range(len(fp_indices)):
		# Choose one of the false positives (e.g., the first one)
		
		chosen_index = fp_indices[idx]

		# Get the feature values for the chosen true positive instance
		chosen_instance_features = X_test.iloc[chosen_index]

		
		for column_name, value in chosen_instance_features.items():
			if value == 1:
				#print(column_name)
				if chosen_index not in false_positive_indices_new:
					false_positive_indices_new.append(chosen_index)
					

	# Print the indexes of false negatives
	print(f"Filtered FP indices: {false_positive_indices_new}")
	print(f"Number of filtered FPs: {len(false_positive_indices_new) }")
	
	
	return 




def close_stdout():
    sys.stdout.close()

# Main Execution


enable_class_weight = False
#enable_class_weight = True

timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

if enable_class_weight:
	redirect_stdout_to_file('results_imbalanced_class_weight_' + timestamp + '.txt')
else:
	redirect_stdout_to_file('results_imbalanced_' + timestamp + '.txt')

target_column = 'Malware'
# Change the folder path accordingly
#dataset_path = '../Resources/permissions/2021/90_10_main_dataset.csv'
dataset_path = '../Resources/permissions-apicalls-xmal/2021/90_10_main_dataset.csv'
#dataset_path = '../Resources/permissions-apicalls-mobi/2021/90_10_main_dataset.csv'

df = load_combined_dataset(dataset_path)

print(f'Dataset path: {dataset_path}')
print(f'enable_class_weight: {enable_class_weight}')


# Calculating the ratio of benign to malware APKs
malware_column = df['Malware']
ratio_ones_to_zeroes = malware_column.value_counts(normalize=True)
print("Ratio of Benign APKs to Malware APKs:")
print(ratio_ones_to_zeroes)

X_train, y_train, X_test, y_test, test_sha256, t_train = prepare_data_for_classification(df, 'Malware')



build_and_evaluate_model(enable_class_weight)
print("\n-------------------------------------------------------------")



print("--------------------")
print(f'DateTime: {timestamp}.')
print("--------------------")
close_stdout()






