from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score,roc_auc_score, confusion_matrix, precision_recall_curve
from sklearn.model_selection import GridSearchCV
import pandas as pd
import sys
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest, chi2
import datetime
import random
import numpy as np
import fasttreeshap





def redirect_stdout_to_file(file_path):
    sys.stdout = open(file_path, 'w')
    



def prepare_data_for_classification(training_data, test_data):


    train = pd.DataFrame(training_data)
    test = pd.DataFrame(test_data)
    # Randomly shuffling the rows of the dataframes
    train = train.sample(frac=1, random_state=42)  # Setting a random seed for reproducibility
    test = test.sample(frac=1, random_state=42)  # Setting a random seed for reproducibility
    train.reset_index(drop=True, inplace=True)
    test.reset_index(drop=True, inplace=True)

    # Calculating the ratio of benign to malware APKs in training set
    malware_column_train = train['Malware']
    ratio_ones_to_zeroes = malware_column_train.value_counts(normalize=True)
    print("TRAINING SET: Ratio of Benign APKs to Malware APKs:")
    print(ratio_ones_to_zeroes)

    # Calculating the ratio of benign to malware APKs
    malware_column_test = test['Malware']
    ratio_ones_to_zeroes = malware_column_test.value_counts(normalize=True)
    print("TEST SET: Ratio of Benign APKs to Malware APKs:")
    print(ratio_ones_to_zeroes)

    
    test_sha256_list = test['sha256']
    
    # Set display options
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    train = train.drop(['sha256'], axis=1)
    test = test.drop(['sha256'], axis=1)

    # Print the names of all columns
    column_names = train.columns
    column_names_list = column_names.to_list()

    for col in column_names_list:
        train[col] = train[col].astype(int)
        test[col] = test[col].astype(int)

    d_train = train.copy() #train without sha256 col
    # Split data into features and target
    X_train = train.drop(columns=['Malware'])
    y_train = train['Malware']

    # Split data into features and target
    X_test = test.drop(columns=['Malware'])
    y_test = test['Malware']
    
       
    return X_train, y_train, X_test, y_test, test_sha256_list, d_train


def build_and_evaluate_model():

	# Parameter Grid for Random Forest
	param_grid_rf = {
		'n_estimators': [50, 100, 200, 500, 1000],
		'max_depth': [None, 10, 16, 20, 30, 40],
		'min_samples_split': [2, 5, 10, 20, 50]
	}
	
	
			
	rf_model = RandomForestClassifier()

	grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1', verbose=2, n_jobs=-1)

	# Fit the models
	grid_search_rf.fit(X_train, y_train)


	# Predict and evaluate using the best model
	best_rf = grid_search_rf.best_estimator_
	print("================RANDOM FOREST RESULTS===================:")
	rf_test_predictions = best_rf.predict(X_test)
	rf_train_predictions = best_rf.predict(X_train)

	print("Best Parameters: ", grid_search_rf.best_params_)

	train_accuracy = accuracy_score(y_train, rf_train_predictions)
	test_accuracy = accuracy_score(y_test, rf_test_predictions)

	train_precision = precision_score(y_train, rf_train_predictions)
	test_precision = precision_score(y_test, rf_test_predictions)

	train_recall = recall_score(y_train, rf_train_predictions)
	test_recall = recall_score(y_test, rf_test_predictions)

	train_f1 = f1_score(y_train, rf_train_predictions)
	test_f1 = f1_score(y_test, rf_test_predictions)

	train_probs = best_rf.predict_proba(X_train)[:, 1]  
	test_probs = best_rf.predict_proba(X_test)[:, 1]

	train_roc_auc = roc_auc_score(y_train, train_probs)
	test_roc_auc = roc_auc_score(y_test, test_probs)

	train_conf_matrix = confusion_matrix(y_train, rf_train_predictions)
	test_conf_matrix = confusion_matrix(y_test, rf_test_predictions)
	#The order in output
	#[[TN, FP],
	#[FN, TP]]
	TN, FP, FN, TP = test_conf_matrix.ravel()

	print(f"Training Accuracy: {train_accuracy}, Test Accuracy: {test_accuracy}")
	print(f"Training Precision: {train_precision}, Test Precision: {test_precision}")
	print(f"Training Recall: {train_recall}, Test Recall: {test_recall}")
	print(f"Training F1 Score: {train_f1}, Test F1 Score: {test_f1}")
	print(f"Training ROC-AUC: {train_roc_auc}, Test ROC-AUC: {test_roc_auc}")
	print(f"Training Confusion Matrix:\n{train_conf_matrix}")
	print(f"Test Confusion Matrix:\n{test_conf_matrix}")
	print("For test dataset:")
	print(f"True Negatives (TN): {TN}")
	print(f"False Positives (FP): {FP}")
	print(f"False Negatives (FN): {FN}")
	print(f"True Positives (TP): {TP}")

	#------------------------------------
	print(classification_report(y_test, rf_test_predictions, labels=[0, 1], target_names=["Benign", "Malware"]))
	
	# Create a test results DataFrame

	test_results_rf = pd.DataFrame({'SHA256': test_sha256, 'Actual Malware': y_test, 'Predicted label':rf_test_predictions})

	#Extract the SHA256 hashes for FPs, FNs, TPs, TNs
	
	fp_hashes = []
	fn_hashes = []
	tn_hashes = []
	tp_hashes = []
	
	for index, row in test_results_rf.iterrows():
		if row['Actual Malware'] == 0 and row['Predicted label'] == 1:
			fp_hashes.append(row['SHA256'])
		elif row['Actual Malware'] == 1 and row['Predicted label'] == 0:	
			fn_hashes.append(row['SHA256'])
		elif row['Actual Malware'] == 0 and row['Predicted label'] == 0:
			tn_hashes.append(row['SHA256'])
		elif row['Actual Malware'] == 1 and row['Predicted label'] == 1:
			tp_hashes.append(row['SHA256'])

	print(f"SHA256 hashes for False Positives (FP): {fp_hashes}")
	print(f"Number of False Positives (FP): {len(fp_hashes)}")
		
	print(f"SHA256 hashes for False Negatives (FN): {fn_hashes}")
	print(f"Number of False Negatives (FN): {len(fn_hashes)}")
	
	#print(f"SHA256 hashes for True Negatives (TN): {tn_hashes}")
	print(f"Number of True Negatives (TN): {len(tn_hashes)}")
	
	#print(f"SHA256 hashes for True Positives (TP): {tp_hashes}")
	print(f"Number of True Positives (TP): {len(tp_hashes)}")
	
	test_results_rf = pd.concat([test_results_rf, X_test], axis=1)

	test_results_rf.to_csv('test_dataset_predictions_rf'+timestamp+'.csv', index=False)
	
		
	
	fp_indices = [i for i in range(len(y_test)) if y_test[i] == 0 and rf_test_predictions[i] == 1]
	fn_indices = [i for i in range(len(y_test)) if y_test[i] == 1 and rf_test_predictions[i] == 0]
	tn_indices = [i for i in range(len(y_test)) if y_test[i] == 0 and rf_test_predictions[i] == 0]
	tp_indices = [i for i in range(len(y_test)) if y_test[i] == 1 and rf_test_predictions[i] == 1]

	
	
	false_negative_indices_new  = []  #stores a subset of FNs in which atleast one feature is equal to one
	
	for idx in range(len(fn_indices)):
		# Choose one of the false negatives (e.g., the first one)
		
		chosen_index = fn_indices[idx]

		# Get the feature values for the chosen false negative instance
		chosen_instance_features = X_test.iloc[chosen_index]

		
		for column_name, value in chosen_instance_features.items():
			if value == 1:
				#print(column_name)
				if chosen_index not in false_negative_indices_new:
					false_negative_indices_new.append(chosen_index)
					

	# Print the indexes of false negatives
	print(f"Filtered FN indices: {false_negative_indices_new }")
	print(f"Number of filtered FNs: {len(false_negative_indices_new) }")
	
	false_positive_indices_new  = []  #stores a subset of FPs in which atleast one feature is equal to one
	
	
	for idx in range(len(fp_indices)):
		# Choose one of the false positives (e.g., the first one)
		
		chosen_index = fp_indices[idx]

		# Get the feature values for the chosen true positive instance
		chosen_instance_features = X_test.iloc[chosen_index]

		
		for column_name, value in chosen_instance_features.items():
			if value == 1:
				#print(column_name)
				if chosen_index not in false_positive_indices_new:
					false_positive_indices_new.append(chosen_index)
					

	# Print the indexes of false negatives
	print(f"Filtered FP indices: {false_positive_indices_new}")
	print(f"Number of filtered FPs: {len(false_positive_indices_new) }")
	
	
	return best_rf, false_negative_indices_new , false_positive_indices_new


 


def close_stdout():
    sys.stdout.close()
    
    
def create_shap_values(ml_model):
	print("\nCreating Fast Tree Shap Value....")
	
	ftree_shap_explainer = fasttreeshap.TreeExplainer(ml_model, algorithm = "auto", n_jobs=-1)
	shap_values = ftree_shap_explainer(X_test).values
	
	print(shap_values)
	
	df_shap = pd.DataFrame(shap_values, columns = feature_names)
	vals = np.abs(df_shap.values).mean(0)
	
	#shap_importance = pd.DataFrame(list(zip(feature_names, vals)), columns=['col_name','feature_importance_vals'])
	
	#shap_importance.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)
	#print(shap_importance.head())
	
	#fasttreeshap.summary_plot(shap_values, features=X_test, feature_names=X_test.columns, plot_type='bar')
	shap_importance = pd.DataFrame(list(zip(feature_names, vals)), columns=['col_name','feature_importance_vals'])
	print(shap_importance )
	
	return	


# Main Execution
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

redirect_stdout_to_file('results_balanced_ftree_shap_' + timestamp + '.txt')


# Example usage of the function

# Change the folder path accordingly
 
#input_train_path = '../Resources/permissions-apicalls-xmal/50_50_train_dataset.csv'
#input_test_path = '../Resources/permissions-apicalls-xmal/90_10_test_dataset.csv'


#input_train_path = '../Resources/permissions-apicalls-mobi/50_50_train_dataset.csv'
#input_test_path = '../Resources/permissions-apicalls-mobi/90_10_test_dataset.csv'

input_train_path = '../Resources/permissions/50_50_train_dataset.csv'
input_test_path = '../Resources/permissions/90_10_test_dataset.csv'


target_column = 'Malware'


train_features_df = pd.read_csv(input_train_path)
test_features_df = pd.read_csv(input_test_path)
print(f'Train set size: {train_features_df.shape}.')
print(f'Test set size: {test_features_df.shape}.')

	


X_train, y_train, X_test, y_test, test_sha256, df_train = prepare_data_for_classification(train_features_df, test_features_df)


#df_train = train_features_df.drop(['sha256'], axis=1)



model, FN_idx, FP_idx = build_and_evaluate_model()
print("\n-------------------------------------------------------------")

feature_names = X_train.columns
create_shap_values(model)



print("--------------------")
print(f'DateTime: {timestamp}.')
print("--------------------")

close_stdout()






